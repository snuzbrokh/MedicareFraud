{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/provData/x_train.csv').set_index('Provider')\n",
    "\n",
    "data.drop(columns = ['Unnamed: 0','Unnamed: 0.1'], inplace=True)\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "data['LargeClaims'] = data['ClaimID'] > 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BeneID</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>NumDiag</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>OPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>TotalClaim</th>\n",
       "      <th>InscCovPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>InscCovPercent_Range</th>\n",
       "      <th>DailyCharge_Range</th>\n",
       "      <th>docDegMax</th>\n",
       "      <th>docBtwnMean</th>\n",
       "      <th>docEignMean</th>\n",
       "      <th>docMANN</th>\n",
       "      <th>patDegMax</th>\n",
       "      <th>patBtwnMean</th>\n",
       "      <th>patEignMean</th>\n",
       "      <th>patMANN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Provider</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PRV51002</td>\n",
       "      <td>71.926829</td>\n",
       "      <td>71</td>\n",
       "      <td>169</td>\n",
       "      <td>205</td>\n",
       "      <td>2.878049</td>\n",
       "      <td>53790</td>\n",
       "      <td>2345.073171</td>\n",
       "      <td>5180.926829</td>\n",
       "      <td>264.243902</td>\n",
       "      <td>0.989728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>9</td>\n",
       "      <td>105.477418</td>\n",
       "      <td>0.144884</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>127</td>\n",
       "      <td>855.435281</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>261.043080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51006</td>\n",
       "      <td>74.343137</td>\n",
       "      <td>43</td>\n",
       "      <td>81</td>\n",
       "      <td>102</td>\n",
       "      <td>3.019608</td>\n",
       "      <td>30720</td>\n",
       "      <td>2401.666667</td>\n",
       "      <td>3767.549020</td>\n",
       "      <td>301.176471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>7</td>\n",
       "      <td>381.813986</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>92</td>\n",
       "      <td>196.902090</td>\n",
       "      <td>0.143410</td>\n",
       "      <td>76.771978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51009</td>\n",
       "      <td>69.102564</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>3.256410</td>\n",
       "      <td>27230</td>\n",
       "      <td>2441.025641</td>\n",
       "      <td>3004.102564</td>\n",
       "      <td>729.948718</td>\n",
       "      <td>0.968461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>47</td>\n",
       "      <td>27.375165</td>\n",
       "      <td>0.089613</td>\n",
       "      <td>119.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51010</td>\n",
       "      <td>74.815789</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>3.447368</td>\n",
       "      <td>64580</td>\n",
       "      <td>1775.789474</td>\n",
       "      <td>5268.421053</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>0.975097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262537</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1012.666667</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>39</td>\n",
       "      <td>76.288550</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>109.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51018</td>\n",
       "      <td>72.915789</td>\n",
       "      <td>66</td>\n",
       "      <td>146</td>\n",
       "      <td>190</td>\n",
       "      <td>2.868421</td>\n",
       "      <td>61620</td>\n",
       "      <td>2812.947368</td>\n",
       "      <td>4738.947368</td>\n",
       "      <td>327.842105</td>\n",
       "      <td>0.969389</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56.532737</td>\n",
       "      <td>0.089660</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>116</td>\n",
       "      <td>290.838499</td>\n",
       "      <td>0.203971</td>\n",
       "      <td>102.975788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  Gender  BeneID  ClaimID   NumDiag  \\\n",
       "Provider                                                 \n",
       "PRV51002  71.926829      71     169      205  2.878049   \n",
       "PRV51006  74.343137      43      81      102  3.019608   \n",
       "PRV51009  69.102564      16      30       39  3.256410   \n",
       "PRV51010  74.815789      23      25       38  3.447368   \n",
       "PRV51018  72.915789      66     146      190  2.868421   \n",
       "\n",
       "          InscClaimAmtReimbursed  OPAnnualReimbursementAmt  \\\n",
       "Provider                                                     \n",
       "PRV51002                   53790               2345.073171   \n",
       "PRV51006                   30720               2401.666667   \n",
       "PRV51009                   27230               2441.025641   \n",
       "PRV51010                   64580               1775.789474   \n",
       "PRV51018                   61620               2812.947368   \n",
       "\n",
       "          IPAnnualReimbursementAmt   TotalClaim  InscCovPercent  ...  \\\n",
       "Provider                                                         ...   \n",
       "PRV51002               5180.926829   264.243902        0.989728  ...   \n",
       "PRV51006               3767.549020   301.176471        1.000000  ...   \n",
       "PRV51009               3004.102564   729.948718        0.968461  ...   \n",
       "PRV51010               5268.421053  1840.000000        0.975097  ...   \n",
       "PRV51018               4738.947368   327.842105        0.969389  ...   \n",
       "\n",
       "          InscCovPercent_Range  DailyCharge_Range  docDegMax  docBtwnMean  \\\n",
       "Provider                                                                    \n",
       "PRV51002              0.777778             6010.0          9   105.477418   \n",
       "PRV51006              0.000000             2100.0          7   381.813986   \n",
       "PRV51009              0.666667             3300.0          2    98.000000   \n",
       "PRV51010              0.262537             5068.0          5  1012.666667   \n",
       "PRV51018              1.000000             3300.0          5    56.532737   \n",
       "\n",
       "          docEignMean    docMANN  patDegMax  patBtwnMean  patEignMean  \\\n",
       "Provider                                                                \n",
       "PRV51002     0.144884   2.466667        127   855.435281     0.149826   \n",
       "PRV51006     0.002511   7.000000         92   196.902090     0.143410   \n",
       "PRV51009     0.000856  14.500000         47    27.375165     0.089613   \n",
       "PRV51010     0.000177   4.285714         39    76.288550     0.041593   \n",
       "PRV51018     0.089660  11.000000        116   290.838499     0.203971   \n",
       "\n",
       "             patMANN  \n",
       "Provider              \n",
       "PRV51002  261.043080  \n",
       "PRV51006   76.771978  \n",
       "PRV51009  119.037313  \n",
       "PRV51010  109.133333  \n",
       "PRV51018  102.975788  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('../data/provData/x_test.csv').set_index('Provider')\n",
    "data_test.drop(columns = ['Unnamed: 0','Unnamed: 0.1'], inplace=True)\n",
    "data_test.fillna(0, inplace=True)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3abea053b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Status'"
     ]
    }
   ],
   "source": [
    "data.Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PotentialFraud\n",
       "0    4097\n",
       "1     464\n",
       "Name: fraudulence, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('PotentialFraud')['fraudulence'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464, 49)\n",
      "(42, 49)\n",
      "(807, 49)\n",
      "(4097, 49)\n"
     ]
    }
   ],
   "source": [
    "print(data.query('PotentialFraud==1 & fraudulence==1').shape)\n",
    "print(data.query('PotentialFraud==1 & fraudulence==0').shape)\n",
    "print(data.query('PotentialFraud==0 & fraudulence==0').shape)\n",
    "print(data.query('PotentialFraud==0 & fraudulence==1').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410, 49)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08576709796672828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "464/5410"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "### Recall\n",
    "Recall (or sensitivity or true positive rate) is the fraction of observations having a true class of 1 (potentially fraudulent) that are being correctly classified as such. Recall is exactly how many of the fradulent providers we are actually classifying as fraudulent.\n",
    "\n",
    "If we have a problem like cancer detection, we would ideally want our system to have very high recall, potentially at the expense of false postives or accuracy in general.\n",
    "\n",
    "### F1 Score\n",
    "F1 score is the harmonic mean of recall and precision, and it can be thought of as a balance of the two. While accuracy also serves this purpose, it can be quite misleading if classes are heavily imbalanced. In our case, only 9% of providers have been labeled as fraudulent and we assume the test set follows the same distribution. \n",
    "\n",
    "For instance, suppose we have a population of 1000 providers and 100 of them are fraudulent. We have a classfication system that produces the following results:\n",
    "\n",
    "- 40 True Positive (correctly identified fraud)\n",
    "- 10 False Positives (incorrectly mistook non-fraud for fraud)\n",
    "- 20 False Negative (failed to identify fraud)\n",
    "- 930 True Negatives (correctly identified non-fraud)\n",
    "\n",
    "In this example, we have 93.0% accuracy while the F1 score is 72.7% (and 80% precision, 67% recall), which seems to be a more useful overall indicator of performance in this case.\n",
    "\n",
    "### ROC Curve and AUC\n",
    "The receiver operating characteristic curve (or ROC curve) is another tool for evaluating the classfication performance of different models. For any given model, the ROC curve plots the tradoff between the false positive rate on the x-axis against the true positive rate (aka Precision) for different choices of thresholds for a binary classifier. In one extreme case, if the classification threshold is 0, then all instances (for non-perfect models) will be classified as 0, leading to a false positive rate of 0, but also a true postive rate of 0. In the other extreme case, a threshold of 1 leads to a true positive rate/recall of 1 but also a false postive rate of 1. \n",
    "\n",
    "In terms of evaluating classification performance, an ROC curve which is closer to the (FPR = 0, TPR = 1) point compared to another indicates that the former model strictly dominates the latter. Beyond just the curve, one summary measure is simply the AUC or (A)rea (U)nder the ROC (C)urve. A completely random model will produce an AUC of 0.5 while a perfect model will have an AUC of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def confusion(x,y,model):\n",
    "    confusion_matrix(y,model.predict(x))\n",
    "    print_cm(confusion_matrix, labels = ['NoFraud','Fraud'])\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "\n",
    "\n",
    "def feature_importance(model, columns, name, note):\n",
    "    coefs = pd.DataFrame(np.dstack((\n",
    "        columns,model.named_steps[name].coef_.round(4)))[0], \n",
    "                         columns = ['Features','Coefficients']).\\\n",
    "    sort_values('Coefficients',ascending=True).set_index('Features')\n",
    "    \n",
    "    coefs.plot(kind='barh', figsize=(9,7))\n",
    "    plt.title(name + ' ' + note)\n",
    "    plt.axvline(x=0, color='.5')\n",
    "    plt.subplots_adjust(left=.3)\n",
    "    \n",
    "    #print(coefs)\n",
    "\n",
    "\n",
    "def logitMetrics(x,y, model):\n",
    "    logit_tr_acc = model.score(x, y)\n",
    "    logit_tr_pr, logit_tr_re, logit_tr_f1, _ = precision_recall_fscore_support(y, model.predict(x))\n",
    "\n",
    "    print(\" Logit Train Accuracy : %1.3f\" % (logit_tr_acc))\n",
    "    print(\" Logit Train Precision: %1.3f (no fraud) and %1.3f (fraud)\" % (logit_tr_pr[0], logit_tr_pr[1]))\n",
    "    print(\" Logit Train Recall   : %1.3f (no fraud) and %1.3f (fraud)\" % (logit_tr_re[0], logit_tr_re[1]))\n",
    "    print(\" Logit Train F1 Score : %1.3f (no fraud) and %1.3f (fraud)\" % (logit_tr_f1[0], logit_tr_f1[1]))\n",
    "    \n",
    "def ROC(x,y, model):\n",
    "    y_probs_logit = pd.DataFrame(model.predict_proba(x))[1]\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_probs_logit)\n",
    "    auc = roc_auc_score(y, y_probs_logit)  # Computes auc\n",
    "    \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw,\n",
    "            label='ROC logit (area = %0.2f)' % auc)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0, 1.02])\n",
    "    plt.ylim([0, 1.02])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['PotentialFraud']\n",
    "X = data.drop(columns = ['Age',\n",
    "                         'State_in',\n",
    "                         'Gender',\n",
    "                         'docEignMean',\n",
    "                         'patEignMean',\n",
    "                         'Alzheimer', \n",
    "                         'HeartFailure',\n",
    "                         'OPAnnualReimbursementAmt',\n",
    "                         'IPAnnualReimbursementAmt',\n",
    "                         'Cancer', \n",
    "                         'ObstrPulmonary', \n",
    "                         'Diabetes',\n",
    "                         'Osteoporasis',\n",
    "#                          'patBtwnMean',\n",
    "#                          'NumProc_Range',\n",
    "#                          'patMANN',\n",
    "#                          'KidneyDisease',\n",
    "                         'IschemicHeart',\n",
    "                         'Depression',\n",
    "                         'WhetherDead',\n",
    "                         'RheumatoidArthritis', \n",
    "                         'Stroke',\n",
    "                         'NumDiag',\n",
    "                         'fraudulence',\n",
    "                         'DupRecord',\n",
    "                         'ClaimDays_in',\n",
    "#                          'docDegMax',\n",
    "#                          'NumChronics_in',\n",
    "                         'PotentialFraud',\n",
    "#                          'ClaimID',\n",
    "                         'TotalClaim_Range',\n",
    "                         'NumChronics_out',\n",
    "                         'NumProc_in',\n",
    "                         'docMANN',\n",
    "#                          'DailyCharge_Range',\n",
    "                         'patDegMax',\n",
    "                         'DailyCharge',\n",
    "                         'ClaimDays_Range',\n",
    "#                          'docBtwnMean',\n",
    "#                          'TotalClaim',\n",
    "#                          'InscCovPercent_Range',\n",
    "#                          'State_out',\n",
    "                         'ClaimDays_out',\n",
    "                         'NumProc_out',\n",
    "                         'AdmissionDays_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "def two_stage_model_predict(X,y):\n",
    "    \n",
    "    ## Stage 1 Classifier\n",
    "    name = 'LogReg'\n",
    "\n",
    "    X_train, X_test, y_train, y_test = tts(X, y,random_state=0, test_size = 1.0/3)\n",
    "\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             (name, LogisticRegression())]\n",
    "\n",
    "    model_stage1 = Pipeline(steps = steps)\n",
    "    _ = model_stage1.fit(X_train,y_train)\n",
    "    \n",
    "    coefs_1 = pd.DataFrame(np.dstack((\n",
    "        X.columns,model_stage1.named_steps[name].coef_.round(4),model_stage1['scaler'].scale_))[0], \n",
    "                         columns = ['Features','Coefficients_1','Scale_1']).\\\n",
    "    sort_values('Coefficients_1',ascending=True).set_index('Features')\n",
    "\n",
    "    ## Stage 2 Classifier\n",
    "    y_pred1 = model_stage1.predict(X)\n",
    "\n",
    "    stage1 = pd.DataFrame({'Target' : y, 'Prediction' : y_pred1})\n",
    "\n",
    "    y_correct1 = stage1.query('Target == Prediction')[['Prediction']]\n",
    "\n",
    "    y_2 = stage1.query('Target != Prediction')['Target']\n",
    "    \n",
    "    idx1 = y_1.index\n",
    "    idx2 = y_2.index\n",
    "    X_1 = data.loc[idx1,:]\n",
    "    X_2 = data.loc[idx2,:]\n",
    "\n",
    "    X_train2, X_test2, y_train2, y_test2 = tts(X_2, y_2,random_state=0, test_size = 1.0/3)\n",
    "\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             (name, LogisticRegression())]\n",
    "\n",
    "    model_stage2 = Pipeline(steps = steps)\n",
    "    _ = model_stage2.fit(X_train2,y_train2)\n",
    "    \n",
    "    coefs_2 = pd.DataFrame(np.dstack((\n",
    "        X_2.columns,model_stage2[name].coef_.round(4),model_stage2['scaler'].scale_))[0], \n",
    "                         columns = ['Features','Coefficients_2','Scale_2']).\\\n",
    "    sort_values('Coefficients_2',ascending=True).set_index('Features')\n",
    "\n",
    "    y_pred2 = model_stage2.predict(X_2)\n",
    "\n",
    "    stage2 = pd.DataFrame({'Target' : y_2, 'Prediction' : y_pred2})\n",
    "\n",
    "    y_correct2 = stage2.query('Target == Prediction')[['Prediction']]\n",
    "\n",
    "    y_pred = y_correct1.append(y_correct2)\n",
    "    \n",
    "    coefs = pd.merge(coefs_1,coefs_2, on='Features').reset_index()\n",
    "    # Sort the index after the append to get all the ducks in a row\n",
    "    return y_pred.sort_index(), coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs['Rescaled_Coef_1'] = coefs['Coefficients_1']/coefs['Scale_1']\n",
    "coefs['Rescaled_Coef_2'] = coefs['Coefficients_2']/coefs['Scale_2']\n",
    "coefs['First'] = coefs['Rescaled_Coef_1'].apply(lambda x: np.exp(x)-1)\n",
    "coefs['Second'] = coefs['Rescaled_Coef_2'].apply(lambda x: np.exp(x)-1)\n",
    "\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coefs.melt(value_vars = ['First','Second'], \n",
    "           id_vars = 'Features', \n",
    "           value_name = 'IncreaseInOdds', \n",
    "           var_name = 'Stage').sort_values('IncreaseInOdds',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.barplot(y = 'Features',x = 'IncreaseInOdds', hue = 'Stage', data=df)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('Increase in Odds (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stage1[name].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['PotentialFraud']\n",
    "X = data[['fraudulence','ClaimID','LargeClaims','DailyCharge_Range','NumProc_in','docMANN',]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=2, test_size = 1.0/5)\n",
    "logit = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "\n",
    "logitMetrics(X_test,y_test,logit)\n",
    "print(confusion_matrix(y_test, logit.predict(X_test)))\n",
    "ROC(X_test,y_test,logit)\n",
    "\n",
    "\n",
    "#feature_importance(logit, X.columns, name, 'Recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['PotentialFraud']\n",
    "X = data.drop(columns = [\n",
    "    'PotentialFraud',\n",
    "    'Age',\n",
    "    'State_in',\n",
    "    'Gender',\n",
    "    'docEignMean',\n",
    "#     'patEignMean',\n",
    "    'patDegMax',\n",
    "    'Alzheimer', \n",
    "    'HeartFailure',\n",
    "    'OPAnnualReimbursementAmt',\n",
    "    'IPAnnualReimbursementAmt',\n",
    "    'Cancer', \n",
    "    'ObstrPulmonary', \n",
    "    'Diabetes',\n",
    "    'Osteoporasis',\n",
    "    'Depression',\n",
    "    'patBtwnMean',\n",
    "#     'NumProc_Range',\n",
    "#     'patMANN',\n",
    "#     'KidneyDisease',\n",
    "#     'IschemicHeart',\n",
    "#     'WhetherDead',\n",
    "    'RheumatoidArthritis',\n",
    "    'InscCovPercent',\n",
    "    'Stroke',\n",
    "#     'fraudulence',\n",
    "    'docDegMax',\n",
    "#     'NumChronics_in',\n",
    "#     'TotalClaim_Range',\n",
    "#     'NumChronics_out',\n",
    "    'NumProc_in',\n",
    "    'docMANN',\n",
    "#     'docBtwnMean',\n",
    "    'State_out',\n",
    "#     'ClaimDays_out',\n",
    "#     'LargeClaims',\n",
    "#     'NumProc_out',\n",
    "    'AdmissionDays_in',\n",
    "    'BeneID',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "name = 'LogReg_Stage1'\n",
    "over = BorderlineSMOTE(sampling_strategy=0.2)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=2, test_size = 1.0/5)\n",
    "X_train1, X_test1, y_train1, y_test1 = tts(X_train, y_train,random_state=6, test_size = 1.0/3)\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         #('o', over),\n",
    "         #('u', under),\n",
    "         (name, LogisticRegressionCV(\n",
    "             Cs = np.logspace(-6,1,20),penalty='l1',\n",
    "             scoring = 'recall',\n",
    "             class_weight = 'balanced',\n",
    "             solver='liblinear',\n",
    "             max_iter=1000))]\n",
    "\n",
    "model_stage1 = Pipeline(steps = steps)\n",
    "_ = model_stage1.fit(X_train1,y_train1)\n",
    "\n",
    "logitMetrics(X_test1,y_test1,model_stage1)\n",
    "print(confusion_matrix(y_test1,model_stage1.predict(X_test1)))\n",
    "ROC(X_test1,y_test1,model_stage1)\n",
    "\n",
    "\n",
    "feature_importance(model_stage1, X.columns, name, 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitMetrics(X_train,y_train,model_stage1)\n",
    "cm = confusion_matrix(y_train,model_stage1.predict(X_train))\n",
    "tn1,fp1,fn1,tp1 = cm.ravel()\n",
    "print(cm)\n",
    "ROC(X_train,y_train,model_stage1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Data for Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = pd.DataFrame({'Prediction' : model_stage1.predict(X_train)}, index = y_train.index)\n",
    "idx1 = y_pred1.query('Prediction==0')[\"Prediction\"].index\n",
    "y_1noFN = y.loc[idx1]\n",
    "idx2 = y_pred1.query('Prediction==1')[\"Prediction\"].index\n",
    "#idx2 = y.index\n",
    "X_2 = X.loc[idx2,:]\n",
    "#X_2['LargeClaims'].value_counts()\n",
    "y_2 = y.loc[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.drop(columns = [\n",
    "#     'ClaimID', \n",
    "#     'NumDiag', \n",
    "    'TotalClaim', \n",
    "#     'DailyCharge',\n",
    "    'DupRecord', \n",
    "    'fraudulence', \n",
    "#     'ClaimDays_in',\n",
    "    'NumChronics_in',\n",
    "    'NumChronics_out', \n",
    "    'fraudulence',\n",
    "#     'NumProc_Range', \n",
    "#     'ClaimDays_Range',\n",
    "#     'TotalClaim_Range', \n",
    "#     'InscCovPercent_Range', \n",
    "#     'DailyCharge_Range'\n",
    "],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'LogReg_Stage2'\n",
    "X_train2, X_test2, y_train2, y_test2 = tts(X_2, y_2,random_state=7, test_size = 1.0/3)\n",
    "\n",
    "over = BorderlineSMOTE(sampling_strategy=0.4)\n",
    "under = RandomUnderSampler(sampling_strategy=0.7)\n",
    "\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         ('o', over),\n",
    "         ('u', under),\n",
    "         (name, LogisticRegressionCV(\n",
    "             Cs = np.logspace(-3,2,20),penalty='l2',\n",
    "             scoring = 'recall_weighted',\n",
    "             class_weight = 'balanced',\n",
    "             solver='liblinear',\n",
    "             max_iter=1000))]\n",
    "\n",
    "model_stage2 = Pipeline(steps = steps)\n",
    "_ = model_stage2.fit(X_train2,y_train2)\n",
    "\n",
    "logitMetrics(X_test2,y_test2,model_stage2)\n",
    "print(confusion_matrix(y_test2,model_stage2.predict(X_test2)))\n",
    "ROC(X_test2,y_test2,model_stage2)\n",
    "\n",
    "feature_importance(model_stage2, X_2.columns, name, 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logitMetrics(X_2,y_2,model_stage2)\n",
    "cm2 = confusion_matrix(y_2,model_stage2.predict(X_2))\n",
    "tn2,fp2,fn2,tp2 = cm2.ravel()\n",
    "print(cm2)\n",
    "ROC(X_2,y_2,model_stage2)\n",
    "\n",
    "y_pred2 = pd.DataFrame({'Prediction' : model_stage2.predict(X_2)}, index = y_2.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out of Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full Train Target Size: \\t\\t{}'.format(y.shape))\n",
    "print('Size for Final Model Evaluation: \\t{}'.format(y_test.shape))\n",
    "\n",
    "\n",
    "print('\\nSize of Target Subset 1st Stage: \\t{}'.format(y_train.shape))\n",
    "print('\\nSize for 1st Stage Training: \\t\\t\\t{}'.format(y_train1.shape))\n",
    "print('Size for 1st Stage Evaluation: \\t\\t\\t{}'.format(y_test1.shape))\n",
    "\n",
    "\n",
    "print('\\nSize withheld from 2nd Stage: \\t\\t{}'.format(y_1noFP.shape))\n",
    "print('Size of Target Subset 2nd Stage: \\t{}'.format(y_2.shape))\n",
    "print('\\nSize for 2nd Stage Training: \\t\\t\\t{}'.format(y_train2.shape))\n",
    "print('Size for 2nd Stage Evaluation: \\t\\t\\t{}'.format(y_test2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred2 = pd.DataFrame({'Prediction' : model_stage2.predict(X_2)}, \n",
    "                       index = y_2.index)\n",
    "\n",
    "# cm2 = confusion_matrix(y_2, y_pred2['Prediction'])\n",
    "# tn2,fp2,fn2,tp2 = cm2.ravel()\n",
    "\n",
    "final_prediction = y_1noFP.append(y_pred2['Prediction']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame({'Prediction1' : model_stage1.predict(X_train),\n",
    "              'Prediction2' : final_prediction}, \n",
    "                           index = y_train.index)\n",
    "df_['and'] = df_['Prediction1'] & df_['Prediction2']\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Prediction1' : model_stage1.predict(X_train),\n",
    "              'Prediction2' : model_stage2.predict(X_train)}, \n",
    "                           index = y_train.index)\n",
    "df['and'] = df['Prediction1'] & df['Prediction2']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train,df['and']))\n",
    "\n",
    "logit_tr_pr, logit_tr_re, logit_tr_f1, _ = precision_recall_fscore_support(y_train, df['and'])\n",
    "\n",
    "print(\" Logit Train Precision: %1.3f (no fraud) and %1.3f (fraud)\" % (logit_tr_pr[0], logit_tr_pr[1]))\n",
    "print(\" Logit Train Recall   : %1.3f (no fraud) and %1.3f (fraud)\" % (logit_tr_re[0], logit_tr_re[1]))\n",
    "print(\" Logit Train F1 Score : %1.3f (no fraud) and %1.3f (fraud)\" % (logit_tr_f1[0], logit_tr_f1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_model(y, y_pred):\n",
    "    reimbursement = data.loc[y.index,'InscClaimAmtReimbursed']\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'actual':y,\n",
    "            'prediction':y_pred,\n",
    "            'reimbursement': reimbursement # total amounts per provider\n",
    "        }\n",
    "    )\n",
    "    cost_of_investigation = 100000\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    \n",
    "    totalclaims =      np.sum(df['reimbursement'])\n",
    "    totaldefrauded =   np.sum(df.query('actual==1')['reimbursement'])\n",
    "    \n",
    "    totalcost =     np.sum(df.query('prediction==1')['prediction'])*cost_of_investigation\n",
    "    totalfalsepos =    np.sum(df.query('prediction==1 & actual==0')['prediction'])*cost_of_investigation\n",
    "    totalrecovered =   np.sum(df.query('prediction==1 & actual==1')['reimbursement'])\n",
    "    \n",
    "    pct_fraud = 100*totaldefrauded/totalclaims\n",
    "    \n",
    "    print('Total Claims are ${:,.0f}'.format(totalclaims))\n",
    "    print('Percentage of claims associated with fraudulent providers are {:.2f} of total claims'.format(pct_fraud))\n",
    "    print('Cost to insurer at 100K per provider investigation ${:,.0f}'.format(totalcost))\n",
    "    print('Total legal costs for investigating non-fradulent providers are %i' %100*totalfalsepos/totalcost,'% of total cost')\n",
    "    print('Total Recovered claims are %i' %100*totalrecovered/totaldefrauded,'% of total claims')\n",
    "    print('Net benefit of model as Pct of total claims is %i' %(totalrecovered/(totalcost + totalfalsepos)),'% of total claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "def two_stage_model_predict(X,y):\n",
    "    \n",
    "    ## Stage 1 Classifier\n",
    "    name = 'LogReg_Stage1'\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = tts(X, y,random_state=0, test_size = 1.0/3)\n",
    "\n",
    "    steps = [('scaler', StandardScaler()),\n",
    "             (name, LogisticRegressionCV(\n",
    "                 Cs = [1e-4],\n",
    "                 penalty='l2',\n",
    "                 scoring = 'recall',\n",
    "                 class_weight = 'balanced',\n",
    "                 solver='liblinear',\n",
    "                 max_iter=1000))]\n",
    "\n",
    "    model_stage1 = Pipeline(steps = steps)\n",
    "    _ = model_stage1.fit(X,y)\n",
    "    \n",
    "#     coefs_1 = pd.DataFrame(np.dstack((\n",
    "#         X.columns,model_stage1.named_steps[name].coef_.round(4),model_stage1['scaler'].scale_))[0], \n",
    "#                          columns = ['Features','Coefficients_1','Scale_1']).\\\n",
    "#     sort_values('Coefficients_1',ascending=True).set_index('Features')\n",
    "\n",
    "    ## Confusion Matrix\n",
    "#     cm = confusion_matrix(y_train,model_stage1.predict(X_train))\n",
    "#     tn1,fp1,fn1,tp1 = cm.ravel()\n",
    "\n",
    "    ## Stage 2 Classifier\n",
    "    \n",
    "    ## Subset data for Stage 2 (Take out all TN and FP)\n",
    "    \n",
    "    y_pred1 = model_stage1.predict(X)\n",
    "    \n",
    "    #leave_out = y_pred1.query('Prediction==0')[\"Prediction\"].index\n",
    "    #to_2nd_stage = y_pred1.query('Prediction==1')[\"Prediction\"].index\n",
    "    \n",
    "    y_1noFN = y.loc[y_pred1 == 0]\n",
    "    X_2 = X.loc[y_pred1 == 1,:]\n",
    "    y_2 = y.loc[y_pred1 == 1]\n",
    "    \n",
    "    ## Stage 2 Model Building\n",
    "    \n",
    "    name = 'LogReg_Stage2'\n",
    "    \n",
    "#     X_train2, X_test2, y_train2, y_test2 = tts(X_2, y_2,random_state=7, \n",
    "#                                                test_size = 1.0/3)\n",
    "\n",
    "#     over = BorderlineSMOTE(sampling_strategy=0.4)\n",
    "#     under = RandomUnderSampler(sampling_strategy=0.7)\n",
    "\n",
    "\n",
    "    steps = [#('scaler', StandardScaler()),\n",
    "             #('o', over),\n",
    "             #('u', under),\n",
    "             (name, LogisticRegressionCV(\n",
    "                 Cs = np.logspace(-3,2,20),penalty='l2',\n",
    "                 scoring = 'f1',\n",
    "                 class_weight = 'balanced',\n",
    "                 solver='liblinear',\n",
    "                 max_iter=1000))]\n",
    "\n",
    "    model_stage2 = Pipeline(steps = steps)\n",
    "    _ = model_stage2.fit(X_2,y_2)\n",
    "\n",
    "    \n",
    "#     coefs_2 = pd.DataFrame(np.dstack((\n",
    "#         X_2.columns,model_stage2[name].coef_.round(4),model_stage2['scaler'].scale_))[0], \n",
    "#                          columns = ['Features','Coefficients_2','Scale_2']).\\\n",
    "#     sort_values('Coefficients_2',ascending=True).set_index('Features')\n",
    "\n",
    "\n",
    "#     y_pred2 = pd.DataFrame({'Prediction' : model_stage2.predict(X_2)}, \n",
    "#                            index = y_2.index)\n",
    "    \n",
    "#     cm2 = confusion_matrix(y_2, y_pred2['Prediction'])\n",
    "#     tn2,fp2,fn2,tp2 = cm2.ravel()\n",
    "    \n",
    "#     final_prediction = y_1noFP.append(y_pred2['Prediction']).sort_index()\n",
    "\n",
    "#     cmf = confusion_matrix(y_train,final_prediction)\n",
    "#     tnf,fpf,fnf,tpf = cmf.ravel()\n",
    "    \n",
    "#     print(tn1,fp1,fn1,tp1,sum([tn1,fp1,fn1,tp1]))\n",
    "#     print(tn2,fp2,fn2,tp2,sum([tn2,fp2,fn2,tp2]))\n",
    "\n",
    "\n",
    "#     print(tnf,fpf,fnf,tpf,sum([tnf,fpf,fnf,tpf]))\n",
    "    \n",
    "    df = pd.DataFrame({'Prediction1' : model_stage1.predict(X_train),\n",
    "              'Prediction2' : model_stage2.predict(X_train)}, \n",
    "                           index = y_train.index)\n",
    "    df['and'] = df['Prediction1'] & df['Prediction2']\n",
    "\n",
    "\n",
    "\n",
    "#     print(cmf)\n",
    "    return df['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=2)\n",
    "\n",
    "#anova_filter = SelectKBest(f_regression, k=10)\n",
    "\n",
    "name = 'LogRegRecall'\n",
    "over = BorderlineSMOTE(sampling_strategy=0.3)\n",
    "under = RandomUnderSampler(sampling_strategy=0.7)\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         #('o', over),\n",
    "         #('u', under),\n",
    "         #('anova',anova_filter),\n",
    "         (name, LogisticRegressionCV(\n",
    "             Cs = np.logspace(-5,1,20),\n",
    "                     penalty='l1',\n",
    "                     scoring = 'f1',\n",
    "                     class_weight = 'balanced',\n",
    "                     solver='liblinear',\n",
    "                     max_iter=1000))]\n",
    "\n",
    "\n",
    "\n",
    "model = Pipeline(steps = steps)\n",
    "_ = model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "logitMetrics(X_test,y_test,model)\n",
    "ROC(X_test,y_test,model)\n",
    "\n",
    "confusion(X_test,y_test,model)\n",
    "\n",
    "\n",
    "feature_importance(model,name,'Ridge Regularization, Normalized Variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "name = 'Ridge_Classifier_Recall'\n",
    "over = BorderlineSMOTE(sampling_strategy=0.2)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8)\n",
    "\n",
    "steps = [#('o', over),\n",
    "         #('u', under),\n",
    "         (name, RidgeClassifierCV(alphas = np.logspace(-2,2,10),\n",
    "                                class_weight='balanced',\n",
    "                                scoring = 'f1_weighted',\n",
    "                                store_cv_values = True))]\n",
    "\n",
    "\n",
    "model = Pipeline(steps = steps)\n",
    "_ = model.fit(x_train,y_train)\n",
    "\n",
    "logitMetrics(x_test,y_test,model);\n",
    "cost_model(x_train,y_train,model);\n",
    "print()\n",
    "cost_model(x_test,y_test,model);\n",
    "#feature_importance(model,name,'Ridge Regularization, Normalized Variables')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV,RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define preprocessor\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "# set the tolerance to a large value to make the example faster\n",
    "logit = LogisticRegression(max_iter=10000, tol=0.1, \n",
    "                           solver = 'liblinear', random_state = 2)\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', scaler), \n",
    "    ('pca', pca), \n",
    "    ('logit', logit)], memory = cachedir)\n",
    "\n",
    "grid_params = {\n",
    "    'logit__C': np.logspace(-4,4,10),\n",
    "    'logit__penalty': ['l1','l2'],\n",
    "    'pca__n_components': [5, 15, 30, 45, 64],\n",
    "    \n",
    "}\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "cv = GridSearchCV(\n",
    "    pipe,\n",
    "    grid_params,\n",
    "    cv = rskf,\n",
    "    scoring = ['f1_weighted'],\n",
    "    refit = False,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = ms.train_test_split(x,y, \n",
    "                                                       test_size=1.0/3, random_state=0)\n",
    "\n",
    "cv.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Recall (No false Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['PotentialFraud']\n",
    "X = data.drop(columns = [\n",
    "    'PotentialFraud',\n",
    "    'Age',\n",
    "    'State_in',\n",
    "    'Gender',\n",
    "    'docEignMean',\n",
    "#     'patEignMean',\n",
    "    'patDegMax',\n",
    "    'Alzheimer', \n",
    "    'HeartFailure',\n",
    "    'OPAnnualReimbursementAmt',\n",
    "    'IPAnnualReimbursementAmt',\n",
    "    'Cancer', \n",
    "    'ObstrPulmonary', \n",
    "    'Diabetes',\n",
    "    'Osteoporasis',\n",
    "    'Depression',\n",
    "    'patBtwnMean',\n",
    "#     'NumProc_Range',\n",
    "    'patMANN',\n",
    "#     'KidneyDisease',\n",
    "#     'IschemicHeart',\n",
    "#     'WhetherDead',\n",
    "    'RheumatoidArthritis',\n",
    "    'InscCovPercent',\n",
    "    'Stroke',\n",
    "    'fraudulence',\n",
    "    'docDegMax',\n",
    "#     'NumChronics_in',\n",
    "#     'TotalClaim_Range',\n",
    "#     'NumChronics_out',\n",
    "    'NumProc_in',\n",
    "    'docMANN',\n",
    "#     'docBtwnMean',\n",
    "    'State_out',\n",
    "#     'ClaimDays_out',\n",
    "#     'LargeClaims',\n",
    "#     'NumProc_out',\n",
    "    'AdmissionDays_in',\n",
    "    'BeneID',\n",
    "])\n",
    "\n",
    "#X.drop(labels = idx, axis=0, inplace=True)\n",
    "#y.drop(labels = idx, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RepeatedStratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-453f2c486077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m search = GridSearchCV(model, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'RepeatedStratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import Memory\n",
    "from shutil import rmtree\n",
    "\n",
    "# # Create a temporary folder to store the transformers of the pipeline\n",
    "# location = 'cachedir'\n",
    "\n",
    "# memory = Memory(location=location, verbose=10)\n",
    "\n",
    "name = 'logreg'\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=0, test_size=1.0/3)\n",
    "\n",
    "#anova_filter = SelectKBest(f_regression, k =4)\n",
    "\n",
    "mutual_info_filter = SelectKBest(mutual_info_classif, k = 5)\n",
    "\n",
    "param_grid = dict(\n",
    "    logreg__penalty = ['l1','l2'],\n",
    "    logreg__C = np.logspace(-4,1,15),\n",
    "    #o__sampling_strategy = np.linspace(0.1,0.5,5),\n",
    "    #logreg__l1_ratio = np.linspace(0,1,10),\n",
    ")\n",
    "                  \n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         #('o', over),\n",
    "         #('u', under),\n",
    "         #('anova', anova_filter),\n",
    "         #('mInfo', mutual_info_filter),\n",
    "         (name, LogisticRegression(\n",
    "                 #C = 1e-4,\n",
    "                 class_weight='balanced',\n",
    "                 solver = 'liblinear',\n",
    "             ))]\n",
    "\n",
    "model = Pipeline(steps = steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 2, random_state = 1)\n",
    "\n",
    "search = GridSearchCV(model, \n",
    "                      cv =cv,\n",
    "                      param_grid=param_grid,\n",
    "                      scoring = 'recall').fit(X_train,y_train)\n",
    "\n",
    "#_ = model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#print(model_.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(class_weight='balanced',\n",
       "                                    solver='liblinear'))])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5cd7d1123c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogitMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mROC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "model = search.best_estimator_\n",
    "y_pred = model.predict(X_test)\n",
    "logitMetrics(X_test,y_test,model);\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "ROC(X_test,y_test,model)\n",
    "cost_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mInfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-57132b6c7320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pd.DataFrame({'Features' : X.columns,\n\u001b[0;32m----> 2\u001b[0;31m               'Mutual_Info' : model.named_steps['mInfo'].scores_}).sort_values('Mutual_Info',ascending=False)\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'mInfo'"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'Features' : X.columns,\n",
    "              'Mutual_Info' : model.named_steps['mInfo'].scores_}).sort_values('Mutual_Info',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_model(y, y_pred):\n",
    "    reimbursement = data.loc[y.index,'InscClaimAmtReimbursed']\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'actual':y,\n",
    "            'prediction':y_pred,\n",
    "            'reimbursement': reimbursement # total amounts per provider\n",
    "        }\n",
    "    )\n",
    "    cost_of_investigation = 100000\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "\n",
    "    totalclaims =      np.sum(df['reimbursement'])\n",
    "    totaldefrauded =   np.sum(df.query('actual==1')['reimbursement'])\n",
    "\n",
    "    totalcost =        np.sum(df.query('prediction==1')['prediction'])*cost_of_investigation\n",
    "    totalfalsepos =    np.sum(df.query('prediction==1 & actual==0')['prediction'])*cost_of_investigation\n",
    "    totalrecovered =   np.sum(df.query('prediction==1 & actual==1')['reimbursement'])\n",
    "\n",
    "    pct_fraud = totaldefrauded/totalclaims\n",
    "    falsepos_pct = totalfalsepos/totalcost\n",
    "    recov_pct = totalrecovered/totaldefrauded\n",
    "    net_benefit_pct = totalrecovered/(totalcost + totalfalsepos)\n",
    "\n",
    "    print('Total Claims are ${:,.0f}'.format(totalclaims))\n",
    "    print('Percentage of total reimbursements associated with fraudulent providers is {:.0%}'.format(pct_fraud))\n",
    "    print('Cost to insurer at 100K per provider investigation ${:,.0f}'.format(totalcost))\n",
    "    print('Total legal costs for investigating non-fradulent providers are {:.0%} of total cost'.format(falsepos_pct))\n",
    "    print('Total Recovered claims are {:.0%} of total defrauded claims'.format(recov_pct))\n",
    "    print('Net benefit of model as Pct of total claims is {:.0%} of total claims'.format(net_benefit_pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-e0bc0b8e834b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                       \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                       \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                       scoring = 'f1').fit(X_train,y_train)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    143\u001b[0m             X_idx_sorted=None):\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alpha\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, chi2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "name = 'ada'\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=4, test_size=1.0/3)\n",
    "\n",
    "#anova_filter = SelectKBest(f_regression, k =4)\n",
    "\n",
    "mutual_info_filter = SelectKBest(mutual_info_classif, k = 5)\n",
    "\n",
    "param_grid = dict(\n",
    "    ada__n_estimators = range(100,401,100),\n",
    "    ada__learning_rate = np.linspace(0.2,1.5,10),\n",
    "    #ada__random_state = range(0,5)\n",
    ")\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         #('o', over),\n",
    "         #('u', under),\n",
    "         #('anova', anova_filter),\n",
    "         #('mInfo', mutual_info_filter),\n",
    "         (name, AdaBoostClassifier(\n",
    "             #n_estimators = 100,\n",
    "             random_state = 0,\n",
    "             learning_rate = 0.2\n",
    "         ))]\n",
    "\n",
    "model = Pipeline(steps = steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 2, random_state = 1)\n",
    "\n",
    "search = GridSearchCV(model, \n",
    "                      param_grid=param_grid,\n",
    "                      cv = cv,\n",
    "                      scoring = 'f1').fit(X_train,y_train)\n",
    "\n",
    "_ = model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# model = search.best_estimator_\n",
    "#print(model_.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "logitMetrics(X_test,y_test,model);\n",
    "cm =confusion_matrix(y_test, y_pred)\n",
    "print(cm/sum(sum(cm)))\n",
    "ROC(X_test,y_test,model)\n",
    "cost_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7a2ef70efcf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m search = GridSearchCV(model, \n\u001b[1;32m     35\u001b[0m                       \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                       scoring = 'f1').fit(X_train,y_train)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    752\u001b[0m             tasks = BatchedCalls(itertools.islice(iterator, batch_size),\n\u001b[1;32m    753\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nested_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                                  self._pickle_cache)\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                 \u001b[0;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice, backend_and_jobs, pickle_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_and_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_and_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                                        \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                                                        **fit_and_score_kwargs)\n\u001b[0;32m--> 713\u001b[0;31m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m    715\u001b[0m                                           cv.split(X, y, groups)))\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# XXX: not handling dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2831\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2833\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2282\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m   2177\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[1;32m   2178\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_KEYWORD_ONLY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m                                     default=default))\n\u001b[0m\u001b[1;32m   2180\u001b[0m     \u001b[0;31m# **kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfunc_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_flags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mCO_VARKEYWORDS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_VAR_POSITIONAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_VAR_KEYWORD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{} parameters cannot have default values'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=4, test_size=1.0/3)\n",
    "\n",
    "#anova_filter = SelectKBest(f_regression, k =10)\n",
    "\n",
    "param_grid = dict(MLP__learning_rate_init = np.linspace(0.05,0.13,5),\n",
    "                  MLP__max_iter = range(500,1000,100)\n",
    "                 )\n",
    "\n",
    "                  \n",
    "\n",
    "name = 'MLP'\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         #('o', over),\n",
    "         #('u', under),\n",
    "         #('anova', anova_filter),\n",
    "         (name, MLPClassifier(random_state=1,\n",
    "                              alpha=0.1,\n",
    "                              #max_iter=500,\n",
    "                              #learning_rate_init=0.1,\n",
    "                              learning_rate='adaptive'))]\n",
    "\n",
    "model = Pipeline(steps = steps)\n",
    "\n",
    "search = GridSearchCV(model, \n",
    "                      param_grid=param_grid,\n",
    "                      scoring = 'f1').fit(X_train,y_train)\n",
    "\n",
    "_ = model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "logitMetrics(X_test,y_test,model);\n",
    "cm =confusion_matrix(y_test, y_pred)\n",
    "print(cm/sum(sum(cm)))\n",
    "ROC(X_test,y_test,model)\n",
    "cost_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        {\n",
    "            'actual':y,\n",
    "            'prediction':y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.query('actual == 0 & prediction == 1').index\n",
    "data.loc[idx,['State_out','BeneID', 'ClaimID', 'NumDiag','NumChronics_out','Diabetes','IschemicHeart','TotalClaim_Range','TotalClaim',\n",
    "       'IPAnnualReimbursementAmt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogitBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=0, test_size=1.0/3)\n",
    "anova_filter = SelectKBest(f_regression, k =10)\n",
    "\n",
    "param_grid = dict(\n",
    "    #lboost__n_estimators = range(100,351,50),\n",
    "    lboost__learning_rate = np.logspace(-3,0,10))\n",
    "\n",
    "                  \n",
    "\n",
    "name = 'lboost'\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         #('o', over),\n",
    "         #('u', under),\n",
    "         #('anova', anova_filter),\n",
    "         (name, LogitBoost(\n",
    "             #n_estimators = 200,\n",
    "             random_state=0))]\n",
    "\n",
    "model = Pipeline(steps = steps)\n",
    "\n",
    "search = GridSearchCV(model, \n",
    "                      param_grid=param_grid,\n",
    "                      scoring = 'f1').fit(X_train,y_train)\n",
    "\n",
    "_ = model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lboost',\n",
       "                 LogitBoost(learning_rate=0.46415888336127775,\n",
       "                            random_state=0))])>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logit Train Accuracy : 0.951\n",
      " Logit Train Precision: 0.965 (no fraud) and 0.787 (fraud)\n",
      " Logit Train Recall   : 0.982 (no fraud) and 0.657 (fraud)\n",
      " Logit Train F1 Score : 0.973 (no fraud) and 0.716 (fraud)\n",
      "[[0.88968958 0.01662971]\n",
      " [0.03215078 0.06152993]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1605   30]\n",
      " [  58  111]]\n",
      "Total Claims are $183,646,890\n",
      "Percentage of total reimbursements associated with fraudulent providers is 53%\n",
      "Cost to insurer at 100K per provider investigation $14,100,000\n",
      "Total legal costs for investigating non-fradulent providers are 21% of total cost\n",
      "Total Recovered claims are 92% of total defrauded claims\n",
      "Net benefit of model as Pct of total claims is 521% of total claims\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "logitMetrics(X_test,y_test,model);\n",
    "cm =confusion_matrix(y_test, y_pred)\n",
    "print(cm/sum(sum(cm)))\n",
    "ROC(X_test,y_test,model)\n",
    "cost_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "F1: 0.62 (+/- 0.02) [MLP]\n",
      "F1: 0.60 (+/- 0.02) [LogitBoost]\n",
      "F1: 0.59 (+/- 0.02) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from logitboost import LogitBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y,random_state=0, test_size=1.0/3)\n",
    "\n",
    "clf3 = MLPClassifier(alpha=0.1, learning_rate='adaptive',\n",
    "                               learning_rate_init=0.09, max_iter=500,\n",
    "                               random_state=1)\n",
    "clf2 = LogitBoost(\n",
    "    n_estimators = 200,\n",
    "    learning_rate=0.46415888336127775,\n",
    "    random_state=0)\n",
    "clf1 = AdaBoostClassifier(learning_rate=0.2, n_estimators=100,\n",
    "                                    random_state=0)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Starting from v0.16.0, StackingCVRegressor supports\n",
    "# `random_state` to get deterministic result.\n",
    "sclf = StackingCVClassifier(classifiers=[clf1, clf2],\n",
    "                            meta_classifier=lr,\n",
    "                            random_state=RANDOM_SEED)\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, sclf], \n",
    "                      ['MLP', \n",
    "                       'LogitBoost', \n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train, cv=3, scoring='f1')\n",
    "    print(\"F1: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=RANDOM_SEED)\n",
    "\n",
    "clf1 = MLPClassifier(alpha=0.1, learning_rate='adaptive',\n",
    "                               learning_rate_init=0.09, max_iter=500,\n",
    "                               random_state=1)\n",
    "clf2 = LogitBoost(\n",
    "    n_estimators = 200,\n",
    "    learning_rate=0.46415888336127775,\n",
    "    random_state=0)\n",
    "clf3 = AdaBoostClassifier(learning_rate=0.2, n_estimators=100,\n",
    "                                    random_state=0)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Starting from v0.16.0, StackingCVRegressor supports\n",
    "# `random_state` to get deterministic result.\n",
    "sclf = StackingCVClassifier(classifiers=[clf1],\n",
    "                            #use_probas = True,\n",
    "                            meta_classifier=lr,\n",
    "                            random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "model = OneVsRestClassifier(sclf).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016797312430011197"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Logit Train Accuracy : 0.903\n",
      " Logit Train Precision: 0.904 (no fraud) and 0.667 (fraud)\n",
      " Logit Train Recall   : 0.999 (no fraud) and 0.011 (fraud)\n",
      " Logit Train F1 Score : 0.949 (no fraud) and 0.023 (fraud)\n",
      "[[9.02015677e-01 5.59910414e-04]\n",
      " [9.63045913e-02 1.11982083e-03]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1611    1]\n",
      " [ 172    2]]\n",
      "Total Claims are $171,723,370\n",
      "Percentage of total reimbursements associated with fraudulent providers is 53%\n",
      "Cost to insurer at 100K per provider investigation $300,000\n",
      "Total legal costs for investigating non-fradulent providers are 33% of total cost\n",
      "Total Recovered claims are 1% of total defrauded claims\n",
      "Net benefit of model as Pct of total claims is 252% of total claims\n"
     ]
    }
   ],
   "source": [
    "# y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "logitMetrics(X_test,y_test,model);\n",
    "cm =confusion_matrix(y_test, y_pred)\n",
    "print(cm/sum(sum(cm)))\n",
    "ROC(X_test,y_test,model)\n",
    "cost_model(y_test, y_pred)\n",
    "\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# for i in range(n_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# plt.figure()\n",
    "# lw = 2\n",
    "# plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "#          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver operating characteristic example')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BeneID</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>NumDiag</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>OPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>TotalClaim</th>\n",
       "      <th>InscCovPercent</th>\n",
       "      <th>...</th>\n",
       "      <th>DailyCharge_Range</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>docDegMax</th>\n",
       "      <th>docBtwnMean</th>\n",
       "      <th>docEignMean</th>\n",
       "      <th>docMANN</th>\n",
       "      <th>patDegMax</th>\n",
       "      <th>patBtwnMean</th>\n",
       "      <th>patEignMean</th>\n",
       "      <th>patMANN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Provider</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PRV51001</td>\n",
       "      <td>78.120000</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>3.640000</td>\n",
       "      <td>104640</td>\n",
       "      <td>2615.200000</td>\n",
       "      <td>17606.000000</td>\n",
       "      <td>4399.200000</td>\n",
       "      <td>0.975656</td>\n",
       "      <td>...</td>\n",
       "      <td>7403.60000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.160885e-03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>263.949347</td>\n",
       "      <td>0.060498</td>\n",
       "      <td>146.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51003</td>\n",
       "      <td>69.553030</td>\n",
       "      <td>54</td>\n",
       "      <td>117</td>\n",
       "      <td>132</td>\n",
       "      <td>5.840909</td>\n",
       "      <td>605670</td>\n",
       "      <td>2678.181818</td>\n",
       "      <td>7568.181818</td>\n",
       "      <td>5090.575758</td>\n",
       "      <td>0.912167</td>\n",
       "      <td>...</td>\n",
       "      <td>29034.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.960140e-06</td>\n",
       "      <td>1.349206</td>\n",
       "      <td>89</td>\n",
       "      <td>621.197352</td>\n",
       "      <td>0.072514</td>\n",
       "      <td>117.974212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51004</td>\n",
       "      <td>71.731544</td>\n",
       "      <td>46</td>\n",
       "      <td>138</td>\n",
       "      <td>149</td>\n",
       "      <td>2.771812</td>\n",
       "      <td>52170</td>\n",
       "      <td>2194.899329</td>\n",
       "      <td>4351.879195</td>\n",
       "      <td>352.214765</td>\n",
       "      <td>0.978485</td>\n",
       "      <td>...</td>\n",
       "      <td>3300.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36.851852</td>\n",
       "      <td>6.073016e-04</td>\n",
       "      <td>3.458333</td>\n",
       "      <td>110</td>\n",
       "      <td>196.289758</td>\n",
       "      <td>0.032412</td>\n",
       "      <td>264.349863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51005</td>\n",
       "      <td>70.021459</td>\n",
       "      <td>511</td>\n",
       "      <td>495</td>\n",
       "      <td>1165</td>\n",
       "      <td>2.805150</td>\n",
       "      <td>280910</td>\n",
       "      <td>2109.733906</td>\n",
       "      <td>3623.991416</td>\n",
       "      <td>244.300429</td>\n",
       "      <td>0.980747</td>\n",
       "      <td>...</td>\n",
       "      <td>4080.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.927091e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151</td>\n",
       "      <td>265.010514</td>\n",
       "      <td>0.268140</td>\n",
       "      <td>788.675936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV51007</td>\n",
       "      <td>68.763889</td>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>33710</td>\n",
       "      <td>1729.722222</td>\n",
       "      <td>3050.000000</td>\n",
       "      <td>513.527778</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>...</td>\n",
       "      <td>3300.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.432718e-03</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>70</td>\n",
       "      <td>84.365494</td>\n",
       "      <td>0.100189</td>\n",
       "      <td>81.688948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV57759</td>\n",
       "      <td>73.428571</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>2.178571</td>\n",
       "      <td>10640</td>\n",
       "      <td>3241.785714</td>\n",
       "      <td>3962.142857</td>\n",
       "      <td>384.642857</td>\n",
       "      <td>0.983401</td>\n",
       "      <td>...</td>\n",
       "      <td>2399.52381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>179.669975</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>253.902655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV57760</td>\n",
       "      <td>60.954545</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2.681818</td>\n",
       "      <td>4770</td>\n",
       "      <td>1492.727273</td>\n",
       "      <td>2785.454545</td>\n",
       "      <td>216.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1097.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.317151e-12</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>29.717647</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>80.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV57761</td>\n",
       "      <td>71.439024</td>\n",
       "      <td>40</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "      <td>2.890244</td>\n",
       "      <td>18470</td>\n",
       "      <td>2928.414634</td>\n",
       "      <td>7026.585366</td>\n",
       "      <td>229.756098</td>\n",
       "      <td>0.935979</td>\n",
       "      <td>...</td>\n",
       "      <td>1900.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>175</td>\n",
       "      <td>1846.092411</td>\n",
       "      <td>0.038613</td>\n",
       "      <td>125.619753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV57762</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1900</td>\n",
       "      <td>2540.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.144593e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.123577</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRV57763</td>\n",
       "      <td>73.601695</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>118</td>\n",
       "      <td>2.694915</td>\n",
       "      <td>43610</td>\n",
       "      <td>3108.898305</td>\n",
       "      <td>3599.237288</td>\n",
       "      <td>372.881356</td>\n",
       "      <td>0.990215</td>\n",
       "      <td>...</td>\n",
       "      <td>3300.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.048246e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>32.106239</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>133.657127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5410 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age  Gender  BeneID  ClaimID   NumDiag  \\\n",
       "Provider                                                 \n",
       "PRV51001  78.120000       9      24       25  3.640000   \n",
       "PRV51003  69.553030      54     117      132  5.840909   \n",
       "PRV51004  71.731544      46     138      149  2.771812   \n",
       "PRV51005  70.021459     511     495     1165  2.805150   \n",
       "PRV51007  68.763889      34      58       72  3.222222   \n",
       "...             ...     ...     ...      ...       ...   \n",
       "PRV57759  73.428571      16      24       28  2.178571   \n",
       "PRV57760  60.954545      17       9       22  2.681818   \n",
       "PRV57761  71.439024      40      67       82  2.890244   \n",
       "PRV57762  68.000000       1       1        1  2.000000   \n",
       "PRV57763  73.601695      56      70      118  2.694915   \n",
       "\n",
       "          InscClaimAmtReimbursed  OPAnnualReimbursementAmt  \\\n",
       "Provider                                                     \n",
       "PRV51001                  104640               2615.200000   \n",
       "PRV51003                  605670               2678.181818   \n",
       "PRV51004                   52170               2194.899329   \n",
       "PRV51005                  280910               2109.733906   \n",
       "PRV51007                   33710               1729.722222   \n",
       "...                          ...                       ...   \n",
       "PRV57759                   10640               3241.785714   \n",
       "PRV57760                    4770               1492.727273   \n",
       "PRV57761                   18470               2928.414634   \n",
       "PRV57762                    1900               2540.000000   \n",
       "PRV57763                   43610               3108.898305   \n",
       "\n",
       "          IPAnnualReimbursementAmt   TotalClaim  InscCovPercent  ...  \\\n",
       "Provider                                                         ...   \n",
       "PRV51001              17606.000000  4399.200000        0.975656  ...   \n",
       "PRV51003               7568.181818  5090.575758        0.912167  ...   \n",
       "PRV51004               4351.879195   352.214765        0.978485  ...   \n",
       "PRV51005               3623.991416   244.300429        0.980747  ...   \n",
       "PRV51007               3050.000000   513.527778        0.985303  ...   \n",
       "...                            ...          ...             ...  ...   \n",
       "PRV57759               3962.142857   384.642857        0.983401  ...   \n",
       "PRV57760               2785.454545   216.818182        1.000000  ...   \n",
       "PRV57761               7026.585366   229.756098        0.935979  ...   \n",
       "PRV57762              15000.000000  1900.000000        1.000000  ...   \n",
       "PRV57763               3599.237288   372.881356        0.990215  ...   \n",
       "\n",
       "          DailyCharge_Range  PotentialFraud  docDegMax  docBtwnMean  \\\n",
       "Provider                                                              \n",
       "PRV51001         7403.60000               0          4   300.000000   \n",
       "PRV51003        29034.00000               1          1     0.000000   \n",
       "PRV51004         3300.00000               0          4    36.851852   \n",
       "PRV51005         4080.00000               1          0     0.000000   \n",
       "PRV51007         3300.00000               0          3     0.000000   \n",
       "...                     ...             ...        ...          ...   \n",
       "PRV57759         2399.52381               0          0     0.000000   \n",
       "PRV57760         1097.50000               0          2     0.666667   \n",
       "PRV57761         1900.00000               0          2     0.000000   \n",
       "PRV57762            0.00000               0          0     0.000000   \n",
       "PRV57763         3300.00000               0          0     0.000000   \n",
       "\n",
       "           docEignMean    docMANN  patDegMax  patBtwnMean  patEignMean  \\\n",
       "Provider                                                                 \n",
       "PRV51001  1.160885e-03   8.000000         46   263.949347     0.060498   \n",
       "PRV51003  2.960140e-06   1.349206         89   621.197352     0.072514   \n",
       "PRV51004  6.073016e-04   3.458333        110   196.289758     0.032412   \n",
       "PRV51005  2.927091e-05   0.000000        151   265.010514     0.268140   \n",
       "PRV51007  5.432718e-03   4.750000         70    84.365494     0.100189   \n",
       "...                ...        ...        ...          ...          ...   \n",
       "PRV57759  0.000000e+00   0.000000         44   179.669975     0.008937   \n",
       "PRV57760  7.317151e-12   4.500000          9    29.717647     0.000225   \n",
       "PRV57761  0.000000e+00  10.500000        175  1846.092411     0.038613   \n",
       "PRV57762  6.144593e-04   0.000000          2     3.123577     0.000024   \n",
       "PRV57763  2.048246e-04   0.000000         38    32.106239     0.012851   \n",
       "\n",
       "             patMANN  \n",
       "Provider              \n",
       "PRV51001  146.343750  \n",
       "PRV51003  117.974212  \n",
       "PRV51004  264.349863  \n",
       "PRV51005  788.675936  \n",
       "PRV51007   81.688948  \n",
       "...              ...  \n",
       "PRV57759  253.902655  \n",
       "PRV57760   80.450000  \n",
       "PRV57761  125.619753  \n",
       "PRV57762   88.000000  \n",
       "PRV57763  133.657127  \n",
       "\n",
       "[5410 rows x 49 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Age','TotalClaim','']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
